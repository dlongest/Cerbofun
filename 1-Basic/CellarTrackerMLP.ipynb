{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cellar Tracker MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "Read the data directly from data.world into a Pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://query.data.world/s/r8VVStpwMgTZlScD_VyeGd6JUEX4fm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "If we look at the columns available to us, there's a few to try out for a classifier:\n",
    "- review/text is the text of the review written by the user\n",
    "- review/userId or review/userName identify the user in question\n",
    "- wine/name references the year, vintner, and name of the wine (so it includes wine/year)\n",
    "- wine/variant is the style of wine\n",
    "- wine/year is the year of vintage\n",
    "\n",
    "review/points is the target column for regression (which could be repurposed into classification if so desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have to deal with nulls. For simplicty, we'll remove them but any normal null imputation options are on the table.\n",
    "\n",
    "clean_df = df[df['review/points'].notnull()]\n",
    "clean_df = clean_df[clean_df['wine/year'].notnull()]\n",
    "\n",
    "# Since we're headed towards a neural network, let's go ahead and use LabelEncoder to convert each wine variant into \n",
    "# a unique ID.  fit_transform will go ahead and both determine and ID encoding plus return the transformed variants\n",
    "# for us to save back into the data frame. \n",
    "encoder = LabelEncoder()\n",
    "clean_df['wine/variantId'] = encoder.fit_transform(clean_df['wine/variant'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shaping\n",
    "\n",
    "Now that we've settled on what we're going to do, we need to shape the data frame into a format learnable for our net.  Unlike other algorithms, neural nets require everything be in a numeric format.  It was for that reason that we encoded the wine/variant names into integers.  We need to take that one step further and one-hot encode them.  Keras provides an easy to_categorical function to handle that for us, which will result in 257 columns (1 for each potential variant).  We also want to use year, which we'll use as-is but one could argue should be similarly encoded.  We need to stack them together into a single Numpy array and then we'll use train_test_split from scikit to break them into train and test sets.  Any validation we need done on our model during training will also come out of the training set.  We'll use the test set after training is complete to truly assess our model's ability to generalize.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variant = np_utils.to_categorical(np.asarray(clean_df['wine/variantId'].values))\n",
    "year = np.asarray(clean_df['wine/year'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = np.column_stack((year, variant))\n",
    "\n",
    "y = np.asarray(clean_df['review/points'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_test, y_train, y_test) = train_test_split(X, y, test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
